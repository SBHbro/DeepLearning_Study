{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0726 03:03:07.607038  8940 deprecation_wrapper.py:119] From d:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0726 03:03:07.625951  8940 deprecation_wrapper.py:119] From d:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0726 03:03:07.630966  8940 deprecation_wrapper.py:119] From d:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0726 03:03:07.662881  8940 deprecation_wrapper.py:119] From d:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0726 03:03:07.667867  8940 deprecation_wrapper.py:119] From d:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 03:03:10.567113  8940 deprecation_wrapper.py:119] From d:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0726 03:03:11.129579  8940 deprecation_wrapper.py:119] From D:\\machinelearning\\github\\Please\\ML\\mrcnn\\model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0726 03:03:11.142543  8940 deprecation.py:323] From D:\\machinelearning\\github\\Please\\ML\\mrcnn\\model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0726 03:03:11.152523  8940 deprecation.py:506] From D:\\machinelearning\\github\\Please\\ML\\mrcnn\\model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W0726 03:03:11.422793  8940 deprecation_wrapper.py:119] From D:\\machinelearning\\github\\Please\\ML\\mrcnn\\model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "W0726 03:03:11.427780  8940 deprecation_wrapper.py:119] From D:\\machinelearning\\github\\Please\\ML\\mrcnn\\model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "W0726 03:03:11.529508  8940 deprecation.py:323] From D:\\machinelearning\\github\\Please\\ML\\mrcnn\\model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from visualize_cv2 import model, display_instances, class_names\n",
    "\n",
    "#######################################영상 뒤집는 방법\n",
    "def Rotate(src, degrees):\n",
    "    if degrees == 90:\n",
    "        dst = cv2.transpose(src) # 행렬 변경 \n",
    "        dst = cv2.flip(dst, 1)   # 뒤집기\n",
    "\n",
    "    elif degrees == 180:\n",
    "        dst = cv2.flip(src, 0)   # 뒤집기\n",
    "\n",
    "    elif degrees == 270:\n",
    "        dst = cv2.transpose(src) # 행렬 변경\n",
    "        dst = cv2.flip(dst, 0)   # 뒤집기\n",
    "    else:\n",
    "        dst = null\n",
    "    return dst\n",
    "#######################################\n",
    "\n",
    "capture = cv2.VideoCapture('videofile.mp4')\n",
    "size = (\n",
    "    int(capture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "    int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    ")\n",
    "codec = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "output = cv2.VideoWriter('videofile_masked.avi', codec, 60.0, size)\n",
    "\n",
    "while(capture.isOpened()):\n",
    "    ret, frame = capture.read()\n",
    "    frame = Rotate(frame,90)\n",
    "    if ret:\n",
    "        # add mask to frame\n",
    "        results = model.detect([frame], verbose=0)\n",
    "        r = results[0]\n",
    "        frame = display_instances(\n",
    "            frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
    "        )\n",
    "        output.write(frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(\"videofile.mp4\")\n",
    "\n",
    "#######################################영상 뒤집는 방법\n",
    "def Rotate(src, degrees):\n",
    "    if degrees == 90:\n",
    "        dst = cv2.transpose(src) # 행렬 변경 \n",
    "        dst = cv2.flip(dst, 1)   # 뒤집기\n",
    "\n",
    "    elif degrees == 180:\n",
    "        dst = cv2.flip(src, 0)   # 뒤집기\n",
    "\n",
    "    elif degrees == 270:\n",
    "        dst = cv2.transpose(src) # 행렬 변경\n",
    "        dst = cv2.flip(dst, 0)   # 뒤집기\n",
    "    else:\n",
    "        dst = null\n",
    "    return dst\n",
    "#######################################\n",
    "\n",
    "while True:\n",
    "    if(capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT)):\n",
    "        capture.open(\"videofile.mp4\")\n",
    "\n",
    "    ret, frame = capture.read()\n",
    "    \n",
    "#########################################\n",
    "    frame = Rotate(frame,90)\n",
    "    \n",
    "###########################################\n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "\n",
    "    if cv2.waitKey(33) > 0: break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
